{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## WS 2019/20 â€“ The Empirical Evaluation of Management Practices I\n",
    "\n",
    "# Exam structure\n",
    "\n",
    "**Total duration**: 1 hour 30 minutes\n",
    "\n",
    "**Working time**: approx. 1 hour\n",
    "\n",
    "**Exam materials**: \n",
    "\n",
    "On the day of the exam, we will provide you with:\n",
    "\n",
    "- A dataset\n",
    "- A Jupyter Notebook template, which contains the general instruction and exam questions\n",
    "- These will be either downloadable online or distributed via a memory stick\n",
    "\n",
    "**Deliverables**: At the end of the exam, you will be asked to hand in your solutions in the prepared Jupyter Notebook (both programming code and written explanations in markup) via upload or on a memory stick. We will give specific instructions on how to name and upload your files.\n",
    "\n",
    "**Auxiliary materials**: open book exam, i.e., all materials are allowed. \n",
    "\n",
    "***However, communication between students is not permitted and if detected will result in failing the exam.***\n",
    "\n",
    "**General structure**: \n",
    "\n",
    "The exam will consist of a combination of three types of questions:\n",
    "\n",
    "i. Questions on conceptual understanding which require only short answers ~ *20 %*;\n",
    "\n",
    "ii. Programming task which analyzes the data provided ~ *40 %*;\n",
    "\n",
    "iii. Interpretation and conceptual questions based on the results of your previous analysis ~ *40 %*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Mock Exam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assignment 1 (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__a)__\tUse the dataset provided in class from Bloom et al. (2012) [AMP_Data.csv] and estimate the following OLS regression and show its output using python (remember to cluster the standard errors on the \"account_id\" level):\n",
    "\n",
    "**Output 1**: $$ ln(sales) = \\alpha + \\beta_{1} * management + \\beta_{2} * ln(emp) + \\beta_{3} * ln(cap) + \\epsilon $$\n",
    "\n",
    "Please give a precise verbal interpretation of the coefficient for management and its statistical significance.   \n",
    "\n",
    "*Note: In the dataset capital (cap) can be found in the column \"ppent\" *\n",
    "\n",
    "<div style=\"text-align: right\"> <b>6 points</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "\n",
    "# read in dataset\n",
    "#path_to_data = 'C:\\Data\\AMP_Data.csv'\n",
    "path_to_data = '~/AMP_Data.csv'\n",
    "df = pd.read_csv(path_to_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          np.log(sales)   R-squared:                       0.684\n",
      "Model:                            OLS   Adj. R-squared:                  0.684\n",
      "Method:                 Least Squares   F-statistic:                     1304.\n",
      "Date:                Wed, 27 Nov 2019   Prob (F-statistic):               0.00\n",
      "Time:                        10:43:02   Log-Likelihood:                -8999.5\n",
      "No. Observations:                7094   AIC:                         1.801e+04\n",
      "Df Residuals:                    7090   BIC:                         1.803e+04\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:              cluster                                         \n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         2.9957      0.143     20.931      0.000       2.715       3.276\n",
      "management        0.3982      0.026     15.392      0.000       0.348       0.449\n",
      "np.log(emp)       0.4907      0.023     21.269      0.000       0.445       0.536\n",
      "np.log(ppent)     0.4300      0.020     22.031      0.000       0.392       0.468\n",
      "==============================================================================\n",
      "Omnibus:                     1746.146   Durbin-Watson:                   0.948\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14266.142\n",
      "Skew:                          -0.950   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.682   Cond. No.                         80.7\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n"
     ]
    }
   ],
   "source": [
    "# output 1\n",
    "output1=smf.ols('np.log(sales)~management+np.log(emp)+np.log(ppent)',data=df).fit(cov_type='cluster',cov_kwds={'groups':df['account_id']})\n",
    "\n",
    "print(output1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "'# Insert your answer here:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "__b)__\tUse the same data set to estimate the following regression:\n",
    "\n",
    "**Output 2**: $$ ln(cap) =  \\alpha + \\beta_{1} * management + \\beta_{2} * ln(emp) + \\epsilon $$\n",
    "\n",
    "Please give a verbal interpretation of the coefficient of management.\n",
    "\n",
    "<div style=\"text-align: right\"> <b>4 points</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          np.log(ppent)   R-squared:                       0.507\n",
      "Model:                            OLS   Adj. R-squared:                  0.507\n",
      "Method:                 Least Squares   F-statistic:                     1164.\n",
      "Date:                Wed, 27 Nov 2019   Prob (F-statistic):               0.00\n",
      "Time:                        10:43:35   Log-Likelihood:                -11126.\n",
      "No. Observations:                7094   AIC:                         2.226e+04\n",
      "Df Residuals:                    7091   BIC:                         2.228e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:              cluster                                         \n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       2.7883      0.149     18.691      0.000       2.496       3.081\n",
      "management      0.3032      0.037      8.179      0.000       0.231       0.376\n",
      "np.log(emp)     0.9846      0.024     41.881      0.000       0.939       1.031\n",
      "==============================================================================\n",
      "Omnibus:                      408.794   Durbin-Watson:                   0.790\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              891.775\n",
      "Skew:                          -0.381   Prob(JB):                    2.26e-194\n",
      "Kurtosis:                       4.561   Cond. No.                         43.8\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n"
     ]
    }
   ],
   "source": [
    "output2=smf.ols('np.log(ppent)~management+np.log(emp)',data=df).fit(cov_type='cluster',cov_kwds={'groups':df['account_id']})\n",
    "\n",
    "print(output2.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "'# Insert your answer here:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__c)__ Suppose you would not control for capital in the first regression (i.e. with which you generated output 1). How can you compute the coefficient of \"management\" arising in such a regression **without** running this additional regression only using regression outputs 1 and 2? Please explain your answer and show how you computed the coefficient. \n",
    "\n",
    "<div style=\"text-align: right\"> <b>6 points</b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider capital as an omitted variable in such a regression of log sales on the management score. We can apply the omitted variable bias formula.\n",
    "\n",
    "rho~ = rho + gamma * Cov(C,X)/V(C)\n",
    "\n",
    "The coefficient of ln(capital) in the short regression of ln(sales) on ln(emp) alone is equal to the coefficient of management in the long regression + the effect of ln(capital) in the long regression * the regression of capital on management score (i.e. the difference in the level of capital associated with a one unit higher management score).\n",
    "That is:\n",
    "\n",
    "rho~ = 0.3982+ 0.4300*0.3032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.528576"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3982+ 0.4300*0.3032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          np.log(sales)   R-squared:                       0.578\n",
      "Model:                            OLS   Adj. R-squared:                  0.578\n",
      "Method:                 Least Squares   F-statistic:                     1688.\n",
      "Date:                Wed, 27 Nov 2019   Prob (F-statistic):               0.00\n",
      "Time:                        10:45:30   Log-Likelihood:                -10029.\n",
      "No. Observations:                7094   AIC:                         2.006e+04\n",
      "Df Residuals:                    7091   BIC:                         2.008e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:              cluster                                         \n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept       4.1947      0.128     32.863      0.000       3.945       4.445\n",
      "management      0.5286      0.030     17.572      0.000       0.470       0.588\n",
      "np.log(emp)     0.9141      0.019     49.270      0.000       0.878       0.950\n",
      "==============================================================================\n",
      "Omnibus:                     1824.289   Durbin-Watson:                   0.850\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             9710.346\n",
      "Skew:                          -1.131   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.266   Cond. No.                         43.8\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n"
     ]
    }
   ],
   "source": [
    "## cross check:\n",
    "output3=smf.ols('np.log(sales)~management+np.log(emp)',data=df).fit(cov_type='cluster',cov_kwds={'groups':df['account_id']})\n",
    "\n",
    "print(output3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__d)__ What does this analysis reveal about the role of capital if you want to estimate the effect of management practices on sales?\n",
    "\n",
    "<div style=\"text-align: right\"> <b>3 points</b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Capital is an important control variable that serves to reduce OVB in the regression of sales on the management score. If I interpret the regression in a causal manner: Not controlling for capital leads to an overestimation of the effect of the management score on sales. The reason is that firms with higher management scores have more capital and capital is associated with sales not only through the management score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__e)__ How do you interpret the R2 in regression Output 1?\n",
    "\n",
    "<div style=\"text-align: right\"> <b>3 points</b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "'# Insert your answer here:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__f)__ What are reasons to use the logarithm of the depended variable sales?\n",
    "\n",
    "<div style=\"text-align: right\"> <b>3 points</b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "'# Insert your answer here:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__g)__ Please investigate empirically whether the strength of the association between sales and management score depends on the firm size (as measured by the number of employees). Run a regression and interpret the results with respect to this research question.\n",
    "\n",
    "<div style=\"text-align: right\"> <b>5 points</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          np.log(sales)   R-squared:                       0.684\n",
      "Model:                            OLS   Adj. R-squared:                  0.684\n",
      "Method:                 Least Squares   F-statistic:                     1229.\n",
      "Date:                Wed, 27 Nov 2019   Prob (F-statistic):               0.00\n",
      "Time:                        10:46:35   Log-Likelihood:                -8999.3\n",
      "No. Observations:                7094   AIC:                         1.801e+04\n",
      "Df Residuals:                    7089   BIC:                         1.804e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:              cluster                                         \n",
      "=================================================================================\n",
      "                    coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         3.1824      0.532      5.977      0.000       2.139       4.226\n",
      "management        0.3380      0.152      2.225      0.026       0.040       0.636\n",
      "np.log(emp)       0.4583      0.084      5.461      0.000       0.294       0.623\n",
      "np.log(ppent)     0.4297      0.020     21.885      0.000       0.391       0.468\n",
      "lnemp_man         0.0105      0.025      0.411      0.681      -0.039       0.060\n",
      "==============================================================================\n",
      "Omnibus:                     1750.413   Durbin-Watson:                   0.949\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14271.474\n",
      "Skew:                          -0.953   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.682   Cond. No.                         629.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          np.log(sales)   R-squared:                       0.684\n",
      "Model:                            OLS   Adj. R-squared:                  0.684\n",
      "Method:                 Least Squares   F-statistic:                     1229.\n",
      "Date:                Wed, 27 Nov 2019   Prob (F-statistic):               0.00\n",
      "Time:                        10:46:35   Log-Likelihood:                -8999.3\n",
      "No. Observations:                7094   AIC:                         1.801e+04\n",
      "Df Residuals:                    7089   BIC:                         1.804e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:              cluster                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "Intercept                  3.1824      0.532      5.977      0.000       2.139       4.226\n",
      "management                 0.3380      0.152      2.225      0.026       0.040       0.636\n",
      "np.log(emp)                0.4583      0.084      5.461      0.000       0.294       0.623\n",
      "management:np.log(emp)     0.0105      0.025      0.411      0.681      -0.039       0.060\n",
      "np.log(ppent)              0.4297      0.020     21.885      0.000       0.391       0.468\n",
      "==============================================================================\n",
      "Omnibus:                     1750.413   Durbin-Watson:                   0.949\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            14271.474\n",
      "Skew:                          -0.953   Prob(JB):                         0.00\n",
      "Kurtosis:                       9.682   Cond. No.                         629.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors are robust to cluster correlation (cluster)\n"
     ]
    }
   ],
   "source": [
    "df['lnemp_man']=np.log(df.emp)*df.management\n",
    "\n",
    "output4=smf.ols('np.log(sales)~management+np.log(emp)+np.log(ppent)+lnemp_man',data=df).fit(cov_type='cluster',cov_kwds={'groups':df['account_id']})\n",
    "\n",
    "print(output4.summary())\n",
    "\n",
    "\n",
    "output4=smf.ols('np.log(sales)~management*np.log(emp)+np.log(ppent)',data=df).fit(cov_type='cluster',cov_kwds={'groups':df['account_id']})\n",
    "\n",
    "print(output4.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The point estimate of the interaction term is positive, which would indicate that the management score has a stronger impact on sales in larger firms. But the standard error is very large such that the effect is statistically insignificant. Moreover, the magnitude of the estimate is very small. Hence, it is unlikely that the effect of the management score on sales strongly depends on firm size as measured by the number of employees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assignment 2 (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "*Your task in this assignment is to use your knowledge of Machine Learning to perform model selection and/or model assessment on the AMP dataset. In particular, you will create and evaluate linear regression models which aim at predicting log(sales) based on 18 management practices. In one instance you will use the 'management' column only, which is the average over all management practice dimensions. In another instance, you will use each of the 18 dimensions explicitly in a regression.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['ln_sales', 'management', 'lean1', 'lean2', 'perf1', 'perf2', 'perf3',\n",
    "        'perf4','perf5', 'perf6', 'perf7', 'perf8', 'perf9', 'perf10', 'talent1',\n",
    "        'talent2','talent3', 'talent4', 'talent5', 'talent6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "__a)__ Subset the data such that the resulting dataframe only contains the columns defined in the list \"cols\" above. From the resulting dataframe, remove all rows which contain 'NaNs' (i.e. missing values) in any of the columns.\n",
    "<div style=\"text-align: right\"> <b>2 points</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['ln_sales'] = np.log(df['sales'])\n",
    "df = df[cols]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Now you want to get an unbiased estimate of the mean squared error of the simple linear regression using only the 'management' column to predict 'log(sales)':* \n",
    "\\begin{equation}\n",
    "ln(sales) = \\alpha + \\beta_1* management + \\epsilon\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "__b)__ Describe the validation set approach (without model selection) and explain why this approach is preferable to using the whole dataset for both model estimation and assessment.\n",
    "<div style=\"text-align: right\"> <b>3 points</b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The validation set approach (without model selection) involves splitting our dataset in to two sets: a training set and a test set. We estimate the model on the training set and evaluate the model's performance on the test set.\n",
    "\n",
    "In general, we want an estimate of the model MSE on the population/independent test set. If we use the whole dataset for both model estimation and model assessment, we are using the predictions of the model on data which the model was trained/already knows. Because the model was trained on this data, and in fact attempted to minimize the MSE on, the resulting estimate will often be too optimistic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__c)__ Split the data into a training set containing 75% of the observations and a test set containing 25% of the observations. Use 181 as the random state to allow for reproducibility and name the variables: X_train, X_test, y_train, y_test.\n",
    "<div style=\"text-align: right\"> <b>2 points</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Insert your code here:\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[cols].drop(columns='ln_sales'), df['ln_sales'],\n",
    "                                                   train_size=0.75, random_state=181)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__d)__ Perform the linear regression on the training set and calculate and print the model's mean squared error on both the training set and the test set.\n",
    "<div style=\"text-align: right\"> <b>4 points</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training MSE: 2.002843880448642\n",
      "test MSE: 1.941813174995886\n"
     ]
    }
   ],
   "source": [
    "# Insert your code here:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X_train[['management']],y_train)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "\n",
    "y_pred_tr = reg.predict(X_train[['management']])\n",
    "y_pred_te = reg.predict(X_test[['management']])\n",
    "\n",
    "print('training MSE:', MSE(y_train, y_pred_tr))\n",
    "\n",
    "print('test MSE:', MSE(y_test, y_pred_te))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__e)__ Please comment on the two error estimates: Does the relationship between the MSE on the training set and test set correspond to your answer in b)? Which of the two is the best estimate of the model's generalization error. Explain your answer.\n",
    "<div style=\"text-align: right\"> <b>4 points</b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here we see that the training MSE is larger than the test MSE. Thus, this is the opposite of our answer to b).\n",
    "\n",
    "This might happen because of the drawback of the validation set approach: Our estimates may heavily depend on the particular splits we make in the data. \n",
    "\n",
    "It could also potentially happen because the linear model with one variable generalizes particularly well. In general, a lower training error is expected when a method easily overfits to the training data, yet, poorly generalizes. This happens usually, but not always, with sophisticated methods that have many parameters.\n",
    "\n",
    "As we know, the test MSE is our unbiased estimate of the model's general performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Now you want to perform both model selection and model assessment on the data. In particular, you would like to (i) find the best model among the simple linear regression using only the 'management' column you used above and a multivariate regression using each management practice dimension explicitly:*\n",
    "\\begin{align}\n",
    "ln(sales) =  &  \\alpha + \\beta_1\\times lean1 + \\beta_2\\times lean2 + \\beta_3\\times perf1 + \\beta_4\\times perf2 + \\beta_5\\times perf3\\\\\n",
    "&+ \\beta_6\\times perf4 + \\beta_7\\times perf5 + \\beta_8\\times perf6 + \\beta_9\\times perf7 + \\beta_{10}\\times perf8 \\\\\n",
    "& + \\beta_{11}\\times perf9 + \\beta_{12}\\times perf10 + \\beta_{13}\\times talent1 + \\beta_{14}\\times talent2 + \\beta_{15}\\times talent3 \\\\\n",
    "& + \\beta_{16}\\times talent4 + \\beta_{17}\\times talent5 + \\beta_{18}\\times talent6 + \\epsilon\n",
    "\\end{align}\n",
    "*and (ii) get an unbiased estimate of the best of these to models.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "__f)__ Describe the validation set approach (with model selection) and explain why this approach is preferable to using the validation set approach you described in b) when performing both model selection and assessment.\n",
    "<div style=\"text-align: right\"> <b>3 points</b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The validation set approach (with model selection) involves splitting our dataset in to three sets: a training set, a validation set and a test set. We estimate the model on the training set, perform model selection on the validation set and evaluate the best model's performance on the test set.\n",
    "\n",
    "If we want to perform model selection and assessment from a list of models, we will usually get a too optimistic estimate if we use the validation set approach (without model selection). The reason for this is that we are estimating the test error from a list of models. It is thus as if we are using this set as a hyper parameter of our model, such that we will likely choose a model which fits the validation set \"too well\" in order to provide an unbiased estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train_new, X_val, y_train_new, y_val = train_test_split(X_train,\n",
    "                                                          y_train,\n",
    "                                                          train_size=2/3,\n",
    "                                                          random_state=181)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "__g)__ The code cell above splits up the training data previously defined into a new training set and a validation set (assuming train_test_split has been imported). Please execute the cell. Now perform the validation set approach (with model selection) in order to choose the best of the two models. For this, please print both models' validation mean squared error. Furthermore, print an unbiased estimate of the best model's mean squared error.\n",
    "<div style=\"text-align: right\"> <b>6 points</b> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val MSE 1: 2.138539385519372 \f",
      " Val MSE 2: 2.105679794400939\n"
     ]
    }
   ],
   "source": [
    "# Insert your code below:\n",
    "cols.remove('ln_sales')\n",
    "cols.remove('management')\n",
    "\n",
    "reg2 = LinearRegression().fit(X_train_new[['management']],y_train_new)\n",
    "reg3 = LinearRegression().fit(X_train_new[cols], y_train_new)\n",
    "\n",
    "y_pred2 = reg2.predict(X_val[['management']])\n",
    "y_pred3 = reg3.predict(X_val[cols])\n",
    "print('Val MSE 1:', MSE(y_val, y_pred2), '\\f Val MSE 2:', MSE(y_val, y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE: 1.9102719949480327\n"
     ]
    }
   ],
   "source": [
    "reg3_ = LinearRegression().fit(X_train[cols], y_train)\n",
    "y_pred3_ = reg3_.predict(X_test[cols])\n",
    "print('test MSE:', MSE(y_test, y_pred3_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__h)__ Comment on your results: Which model appear to be the best of the two? Give a potential reason for this.\n",
    "<div style=\"text-align: right\"> <b>3 points</b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The multivariate regression appears to be the better of the two models as it has a lower MSE on the validation set. \n",
    "\n",
    "A potential reason for this could be that using the 18 dimensions instead of the simple mean of these dimensions provide more information which in turn helps predict ln sales.\n",
    "\n",
    "*Note that it makes perfect sense that the validation error is higher than the test error here: We initial train the model on 50% of the data and predict on 25% to get the validation error. Afterwards, we fit the model on 75% of the data and predict on 25 % to get the test error.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__i)__ What is the potential drawback of the validation set approach? Describe a method you have learned about which may remedy this.\n",
    "<div style=\"text-align: right\"> <b>3 points</b> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When using the validation set approach both with and without model selection, the results we get may depend heavily on the particular split(s) of the data. Thus, if we would choose a different split, we may end up with very different estimates.\n",
    "\n",
    "A method to remedy this is K-Fold Cross Valiation. Here we divide the data into K parts, and train the model K times on K-1 parts of the data and evaluate it on the last K part. In order to get the estimate of error for a particular model, we take the average of these K error estimates.\n",
    "\n",
    "*Note that after performing model selection, we still need an independent test set to get an unbiased estimate of model performance of the best model. Alternative methods such as Nested Cross Validation exists to further remedy the problem, but we did not explicitly cover these in class.*"
   ]
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Course Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "207.7px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
